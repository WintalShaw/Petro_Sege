import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import io
import time  # å¼•å…¥timeæ¨¡å—ç”¨äºå®ç°å»¶æ—¶

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams.update({'font.size': 16})

# --- å…¨å±€å›ºå®šå‚æ•° ---
MAX_ERROR = 50
SLOPE_THRESHOLD = 2

# --- åº”ç”¨é…ç½® ---
st.set_page_config(page_title="æ²¹æ°”åºåˆ—åˆ†æ®µä¸åˆ†æå·¥å…·", layout="wide")
st.title("æ²¹æ°”åºåˆ—åˆ†æ®µä¸åˆ†æå·¥å…·")


# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

# ã€æ–°å¢ã€‘æ‰“å­—æœºæ•ˆæœå‡½æ•°
def stream_text_to_placeholder(text, placeholder, delay=0.02):
    """
    å°†æ–‡æœ¬ä»¥æ‰“å­—æœºæ•ˆæœæµå¼è¾“å‡ºåˆ°Streamlitçš„å ä½ç¬¦ä¸­ã€‚
    - text: è¦æ˜¾ç¤ºçš„å®Œæ•´æ–‡æœ¬ã€‚
    - placeholder: st.empty() åˆ›å»ºçš„å ä½ç¬¦å¯¹è±¡ã€‚
    - delay: æ¯ä¸ªå­—ç¬¦æ˜¾ç¤ºçš„å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ã€‚
    """
    displayed_text = ""
    # æ·»åŠ ä¸€ä¸ªæ¨¡æ‹Ÿçš„å…‰æ ‡
    cursor = "â–Œ"
    for char in text:
        displayed_text += char
        placeholder.markdown(displayed_text + cursor, unsafe_allow_html=True)
        time.sleep(delay)
    # å¾ªç¯ç»“æŸåï¼Œæ˜¾ç¤ºå®Œæ•´æ–‡æœ¬å¹¶ç§»é™¤å…‰æ ‡
    placeholder.markdown(displayed_text, unsafe_allow_html=True)


def piecewise_linear_representation(x, y, max_error):
    """åˆ†æ®µçº¿æ€§è¡¨ç¤ºç®—æ³•"""
    segments = []
    n = len(x)
    i = 0
    while i < n - 1:
        j = i + 1
        while j < n:
            if len(x[i:j + 1]) < 2:
                j += 1
                continue

            coeff = np.polyfit(x[i:j + 1], y[i:j + 1], 1)
            fit = np.poly1d(coeff)
            error = np.max(np.abs(y[i:j + 1] - fit(x[i:j + 1])))

            if error > max_error:
                break
            j += 1

        end_point = j - 1
        if end_point <= i:
            end_point = i + 1

        segments.append((i, end_point))
        i = end_point

        if i == n - 2 and end_point == n - 2:
            segments.append((n - 2, n - 1))
            break

    return segments


def generate_analysis_report(df, segments, line_name, anomaly_detected, slope_threshold):
    """ç”Ÿæˆè¯¦ç»†çš„ã€éæœºæ¢°åŒ–çš„åˆ†ææŠ¥å‘Š"""
    report_lines = []

    report_lines.append(f"## {line_name} åºåˆ—åˆ†æ®µåˆ†ææŠ¥å‘Š")
    report_lines.append("---")
    start_report_date = df['date'].iloc[0].strftime('%Y-%m-%d')
    end_report_date = df['date'].iloc[-1].strftime('%Y-%m-%d')
    report_lines.append(f"**åˆ†æå‘¨æœŸ:** ä» {start_report_date} åˆ° {end_report_date}")
    report_lines.append(f"**åˆ†ææ•°æ®åˆ—:** {line_name}")
    report_lines.append(f"**æ€»åˆ†æ®µæ•°:** {len(segments)} æ®µ")
    report_lines.append("\n### æ€»ä½“è¶‹åŠ¿åˆ†æ")

    overall_start_val = df[line_name].iloc[0]
    overall_end_val = df[line_name].iloc[-1]
    overall_change = overall_end_val - overall_start_val
    if overall_change > 0:
        overall_trend = f"åœ¨æ•´ä¸ªåˆ†æå‘¨æœŸå†…ï¼Œæ•°å€¼æ•´ä½“å‘ˆç° **ä¸Šå‡** è¶‹åŠ¿ï¼Œä» {overall_start_val:.2f} å¢é•¿åˆ° {overall_end_val:.2f}ã€‚"
    elif overall_change < 0:
        overall_trend = f"åœ¨æ•´ä¸ªåˆ†æå‘¨æœŸå†…ï¼Œæ•°å€¼æ•´ä½“å‘ˆç° **ä¸‹é™** è¶‹åŠ¿ï¼Œä» {overall_start_val:.2f} å‡å°‘åˆ° {overall_end_val:.2f}ã€‚"
    else:
        overall_trend = f"åœ¨æ•´ä¸ªåˆ†æå‘¨æœŸå†…ï¼Œæ•°å€¼æ•´ä½“ä¿æŒç¨³å®šï¼Œç»´æŒåœ¨ {overall_start_val:.2f} æ°´å¹³ã€‚"
    report_lines.append(overall_trend)
    report_lines.append("\n### å„åˆ†æ®µè¯¦ç»†è§£è¯»")

    for idx, (start, end) in enumerate(segments):
        seg_start_date = df['date'].iloc[start].strftime('%Y-%m-%d')
        seg_end_date = df['date'].iloc[end].strftime('%Y-%m-%d')
        seg_start_val = df[line_name].iloc[start]
        seg_end_val = df[line_name].iloc[end]
        duration = (df['date'].iloc[end] - df['date'].iloc[start]).days + 1

        if end > start:
            slope = (seg_end_val - seg_start_val) / (end - start)
        else:
            slope = 0

        if abs(slope) < 0.5:
            trend_desc = "è¶‹åŠ¿å¹³ç¨³æœŸ"
            analysis = f"æ•°å€¼åœ¨æ­¤é˜¶æ®µè¡¨ç°ç¨³å®šï¼Œæ³¢åŠ¨è¾ƒå°ï¼Œç»´æŒåœ¨ {seg_start_val:.2f} é™„è¿‘ã€‚"
        elif slope > slope_threshold:
            trend_desc = "å¿«é€Ÿå¢é•¿æœŸ"
            analysis = f"æ•°å€¼å‘ˆç°å¿«é€Ÿå¢é•¿ï¼Œä» {seg_start_val:.2f} ä¸Šå‡è‡³ {seg_end_val:.2f}ï¼Œè¡¨æ˜äº†ç§¯æçš„å˜åŒ–ã€‚"
        elif slope > 0:
            trend_desc = "ç¼“æ…¢å¢é•¿æœŸ"
            analysis = f"æ•°å€¼åœ¨æ­¤é˜¶æ®µå¹³ç¼“ä¸Šå‡ï¼Œä» {seg_start_val:.2f} å¢é•¿åˆ° {seg_end_val:.2f}ã€‚"
        elif slope < -slope_threshold:
            trend_desc = "å¿«é€Ÿä¸‹é™æœŸ"
            analysis = f"æ•°å€¼å‡ºç°æ˜¾è‘—ä¸‹é™ï¼Œä» {seg_start_val:.2f} é”å‡è‡³ {seg_end_val:.2f}ï¼Œå¯èƒ½éœ€è¦å…³æ³¨å…¶åŸå› ã€‚"
        else:
            trend_desc = "ç¼“æ…¢ä¸‹é™æœŸ"
            analysis = f"æ•°å€¼åœ¨æ­¤é˜¶æ®µå¹³ç¼“å›è½ï¼Œä» {seg_start_val:.2f} å‡å°‘åˆ° {seg_end_val:.2f}ã€‚"

        report_lines.append(f"\n**åˆ†æ®µ {idx + 1}: {trend_desc} ({seg_start_date} to {seg_end_date})**")
        report_lines.append(f"- **æŒç»­æ—¶é—´:** {duration} å¤©")
        report_lines.append(f"- **æ•°å€¼å˜åŒ–:** ä» {seg_start_val:.2f} åˆ° {seg_end_val:.2f}")
        report_lines.append(f"- **åˆ†æè§£è¯»:** {analysis}")

    report_lines.append("\n### ç»“è®ºä¸å»ºè®®")
    if anomaly_detected:
        anomaly_text = "é‡è¦æé†’ï¼šåˆ†ææ˜¾ç¤ºï¼Œæ•°æ®æœ«ç«¯å‡ºç°äº†å¼‚å¸¸æ³¢åŠ¨ï¼ˆæœ€åä¸€ä¸ªåˆ†æ®µè¿‡çŸ­ï¼‰ï¼Œè¿™é€šå¸¸æ„å‘³ç€è¿‘æœŸäº§é‡æˆ–å‹åŠ›å‘ç”Ÿäº†æ€¥å‰§å˜åŒ–ã€‚å»ºè®®ç«‹å³æ ¸æŸ¥ç›¸å…³ç”Ÿäº§åŠ¨æ€æˆ–è®¾å¤‡çŠ¶å†µï¼Œå¹¶é‡‡å–ç›¸åº”æªæ–½ã€‚"
        report_lines.append(f"**<font color='red'>ã€å¼‚å¸¸é¢„è­¦ã€‘</font>** {anomaly_text}")
    else:
        report_lines.append("å½“å‰åºåˆ—æ•´ä½“å˜åŒ–ç¬¦åˆåˆ†æ®µè¶‹åŠ¿ï¼Œæœªæ£€æµ‹åˆ°æœ«ç«¯çªå˜å¼‚å¸¸ã€‚å»ºè®®æŒç»­ç›‘æ§æ•°æ®å˜åŒ–ã€‚")

    return "\n".join(report_lines)


# --- Streamlit UI å¸ƒå±€ ---

if 'df' not in st.session_state:
    st.session_state.df = None
if 'original_filename' not in st.session_state:
    st.session_state.original_filename = None

with st.sidebar:
    st.header("1. æ•°æ®ä¸Šä¼ ä¸è®¾ç½®")
    uploaded_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type="csv")

    if uploaded_file is not None:
        if uploaded_file.name != st.session_state.original_filename:
            try:
                df = pd.read_csv(uploaded_file)
                if 'date' not in df.columns:
                    st.error("CSVæ–‡ä»¶ä¸­å¿…é¡»åŒ…å« 'date' åˆ—ã€‚")
                    st.session_state.df = None
                else:
                    df['date'] = pd.to_datetime(df['date'])
                    df = df.sort_values(by='date').reset_index(drop=True)
                    st.session_state.df = df
                    st.session_state.original_filename = uploaded_file.name
                    st.success(f"æ–‡ä»¶ '{uploaded_file.name}' åŠ è½½æˆåŠŸï¼")
            except Exception as e:
                st.error(f"åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                st.session_state.df = None

    if st.session_state.df is not None:
        df = st.session_state.df
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        line_name = st.selectbox("é€‰æ‹©è¦åˆ†æçš„æ•°æ®åˆ—:", options=numeric_cols)

        st.header("2. æ—¥æœŸé€‰æ‹©")
        dates_options = st.session_state.df['date'].dt.strftime('%Y-%m-%d').tolist()
        start_date = st.selectbox("é€‰æ‹©åˆ†æ®µå¼€å§‹æ—¥æœŸ:", options=dates_options)

if st.session_state.df is None:
    st.info("è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ ä¸€ä¸ªCSVæ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
    st.markdown("---")
    st.markdown("...")  # çœç•¥æç¤ºä¿¡æ¯
else:
    df = st.session_state.df

    with st.expander("ğŸ“ æ·»åŠ æ–°æ•°æ®ç‚¹ (å¯é€‰)"):
        col1, col2 = st.columns(2)
        with col1:
            new_value = st.text_input("è¾“å…¥æ–°æ•°å€¼:", key="new_val_input")
        with col2:
            st.write("")
            st.write("")
            if st.button("ç¡®å®šæ–°å¢", key="add_data_btn"):
                if new_value and 'line_name' in locals() and line_name:
                    try:
                        current_df = st.session_state.df.copy()
                        last_date = current_df['date'].iloc[-1]
                        new_date = last_date + pd.Timedelta(days=1)

                        new_row_data = {'date': new_date}
                        for col in current_df.columns:
                            if col != 'date':
                                new_row_data[col] = np.nan
                        new_row_data[line_name] = float(new_value)

                        new_row = pd.DataFrame([new_row_data])

                        st.session_state.df = pd.concat([current_df, new_row], ignore_index=True)
                        st.success(f"æ–°å¢æˆåŠŸï¼æ—¥æœŸ: {new_date.strftime('%Y-%m-%d')}, æ•°å€¼: {float(new_value)}")
                        st.rerun()

                    except ValueError:
                        st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼ï¼")
                    except Exception as e:
                        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
                else:
                    st.warning("è¯·è¾“å…¥æ•°å€¼å¹¶é€‰æ‹©è¦åˆ†æçš„æ•°æ®åˆ—ã€‚")

    st.markdown("---")
    st.subheader("æ•°æ®é¢„è§ˆä¸ä¸‹è½½")
    st.dataframe(st.session_state.df.tail())

    csv_buffer = io.StringIO()
    st.session_state.df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')

    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ä¿®æ”¹åçš„CSVæ–‡ä»¶",
        data=csv_buffer.getvalue(),
        file_name=f"updated_{st.session_state.original_filename}",
        mime="text/csv"
    )

    st.markdown("---")
    if st.button("ğŸš€ å¼€å§‹åˆ†æ®µä¸ç”ŸæˆæŠ¥å‘Š", type="primary"):
        with st.spinner("æ­£åœ¨è¿›è¡Œè®¡ç®—åˆ†æï¼Œè¯·ç¨å€™..."):
            # è¿™éƒ¨åˆ†è®¡ç®—é€»è¾‘ä¸å˜
            selected_start_date = pd.to_datetime(start_date)
            analysis_df = st.session_state.df[st.session_state.df['date'] >= selected_start_date].copy().reset_index(
                drop=True)

            if analysis_df.empty or len(analysis_df) < 2:
                st.error("æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
            else:
                dates = analysis_df['date'].values
                daily_values = analysis_df[line_name].values
                segments = piecewise_linear_representation(np.arange(len(dates)), daily_values, MAX_ERROR)

                anomaly_detected = False
                if segments and len(segments) > 1:
                    last_seg_start, last_seg_end = segments[-1]
                    if last_seg_end - last_seg_start <= 1:
                        anomaly_detected = True
                        st.warning("ã€å¼‚å¸¸é¢„è­¦ã€‘æ•°æ®æœ«ç«¯å‡ºç°å‰§çƒˆæ³¢åŠ¨ï¼Œæœ€åä¸€ä¸ªåˆ†æ®µè¿‡çŸ­ï¼Œè¯·å…³æ³¨æœ€æ–°åŠ¨æ€ï¼")

        # spinner ç»“æŸåï¼Œå¼€å§‹æ˜¾ç¤ºç»“æœ
        st.header("åˆ†æç»“æœ")

        # 1. ç»˜åˆ¶å›¾è¡¨ (è¿™éƒ¨åˆ†æ˜¯ç¬æ—¶å®Œæˆçš„)
        fig, ax = plt.subplots(figsize=(15, 7))
        ax.plot(dates, daily_values, 'o-', label='original_data', color='cornflowerblue', markersize=3, alpha=0.7)
        segment_point_indices = []
        if segments:
            segment_point_indices.append(segments[0][0])
            for start, end in segments:
                segment_point_indices.append(end)
            segment_point_indices = sorted(list(set(segment_point_indices)))

        for idx, (start, end) in enumerate(segments):
            seg_dates, seg_values = dates[start:end + 1], daily_values[start:end + 1]
            if anomaly_detected and idx == len(segments) - 1:
                ax.plot(seg_dates, seg_values, color='orangered', linewidth=3, linestyle='--', label=f'Abnormal_segement')
            else:
                label = 'Trend_segement' if idx == 0 else "_nolegend_"
                ax.plot(seg_dates, seg_values, color='red', linewidth=3, label=label)

        if segment_point_indices:
            point_dates, point_values = dates[segment_point_indices], daily_values[segment_point_indices]
            ax.scatter(point_dates, point_values, color='green', s=100, zorder=5, label='åˆ†æ®µç‚¹')

        # --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘åœ¨åˆ†æ®µç‚¹ä¸Šæ ‡æ³¨æ—¥æœŸ ---
        # åŠ¨æ€è®¡ç®—æ–‡æœ¬çš„å‚ç›´åç§»é‡ï¼Œä½¿å…¶èƒ½è‡ªé€‚åº”ä¸åŒæ•°å€¼èŒƒå›´çš„å›¾è¡¨
        y_min, y_max = ax.get_ylim()
        y_offset = (y_max - y_min) * 0.02  # åç§»é‡ä¸ºYè½´èŒƒå›´çš„2%

        for date, value in zip(point_dates, point_values):
            # ä½¿ç”¨ æœˆ-æ—¥ æ ¼å¼é¿å…æ ‡ç­¾è¿‡é•¿å¯¼è‡´é‡å 
            date_str = pd.to_datetime(date).strftime('%m-%d')
            ax.text(
                x=date,
                y=value + y_offset,  # åœ¨ç‚¹çš„ä¸Šæ–¹æ˜¾ç¤ºæ–‡æœ¬
                s=date_str,
                ha='center',  # æ°´å¹³å±…ä¸­å¯¹é½
                va='bottom',  # å‚ç›´åº•éƒ¨å¯¹é½
                fontsize=9,
                color='dimgray',  # ä½¿ç”¨æ·±ç°è‰²ï¼Œé¿å…å–§å®¾å¤ºä¸»
                fontweight='bold'
            )
        # --- ã€ä¿®æ”¹ç»“æŸã€‘ ---

        ax.set_title(f"{line_name} Segement_result", fontsize=16)
        ax.set_xlabel("date", fontsize=12)
        ax.set_ylabel(line_name, fontsize=12)
        ax.legend()
        ax.grid(True, linestyle='--', alpha=0.6)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # 2. ç”Ÿæˆå¹¶ä»¥æ‰“å­—æœºæ•ˆæœæ˜¾ç¤ºæŠ¥å‘Š
        st.subheader("ğŸ“œ åˆ†ææŠ¥å‘Š")
        report_content = generate_analysis_report(analysis_df, segments, line_name, anomaly_detected, SLOPE_THRESHOLD)

        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘åˆ›å»ºå ä½ç¬¦å¹¶è°ƒç”¨æ‰“å­—æœºå‡½æ•°
        report_placeholder = st.empty()
        stream_text_to_placeholder(report_content, report_placeholder, delay=0.015)  # è°ƒæ•´ delay å¯ä»¥æ”¹å˜æ‰“å­—é€Ÿåº¦

        # 3. æä¾›æŠ¥å‘Šä¸‹è½½ (ä¸‹è½½æŒ‰é’®åœ¨æŠ¥å‘Šâ€œæ‰“å®Œâ€åå‡ºç°)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š (.txt)",
            data=report_content.encode('utf-8'),
            file_name=f"{line_name}_analysis_report.txt",
            mime="text/plain"
        )
